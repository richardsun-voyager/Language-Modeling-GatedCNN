{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep contextualized word representation has drawn wide attention because of state-of-the-art performances in downstream tasks. Contextualized embeddings can capture not only word-level information but also multi-sense information, thus improving the results in sentiment analysis, SQuad and etc. However, the language adopted in the [Elmo](https://allennlp.org/elmo) model were biLSTMs which contained a huge number of parameters, it was less likely for small labs to train and run such experiments.\n",
    "\n",
    "\n",
    "In this project, we intend to make use of CNN language model in learning efficient word representations for sentiment analysis. We train a language model based on [Gated CNN architecture](https://arxiv.org/abs/1612.08083) proposed by Yann Daulphin, then do sentiment analysis with embeddings generated by the language model.\n",
    "\n",
    "The language model training dataset is 1-billion-word-language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from bilm.training import load_options_latest_checkpoint, load_vocab\n",
    "from bilm.data import Batcher, BidirectionalLMDataset\n",
    "from conf_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the configuration and prepare data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/vocab-2016-09-10.txt') as f:\n",
    "    #lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the words\n",
    "vocab_file = 'data/vocab-2016-09-10.txt'\n",
    "vocab_file = 'data/wiki-vocab.txt'\n",
    "vocab = load_vocab(vocab_file, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    vocab_size = vocab.size\n",
    "    embedding_size = 128\n",
    "    filter_size = 64\n",
    "    num_layers = 3\n",
    "    block_size = 3\n",
    "    filter_h = 5\n",
    "    context_size = 50\n",
    "    text_size = context_size\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    num_sampled = 64\n",
    "    learning_rate = 1\n",
    "    momentum = 0.99\n",
    "    grad_clip = 0.1\n",
    "    num_batches = 0\n",
    "    ckpt_path = 'ckpt_char_gated_cnn'\n",
    "    summary_path = 'logs'\n",
    "    #data_dir = \"data/texts/reviews/movie_reviews\"\n",
    "    data_dir = \"data/1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_config:\n",
    "    vocab_size = vocab.size\n",
    "    embedding_size = 128\n",
    "    filter_size = 64\n",
    "    num_layers = 3\n",
    "    block_size = 3\n",
    "    filter_h = 5\n",
    "    context_size = 50\n",
    "    text_size = context_size\n",
    "    batch_size = 1\n",
    "    epochs = 5\n",
    "    num_sampled = 64\n",
    "    learning_rate = 1\n",
    "    momentum = 0.99\n",
    "    grad_clip = 0.1\n",
    "    num_batches = 0\n",
    "    ckpt_path = 'ckpt_char_gated_cnn'\n",
    "    summary_path = 'logs'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize configuration files\n",
    "conf = prepare_conf(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a CharCNN-based language model\n",
    "\n",
    "Note the inputs are transformed into chars of words, so as to make use of subword information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Model Training...\n"
     ]
    }
   ],
   "source": [
    "#Create a language model\n",
    "#Note we need to save the models for subsequent tasks\n",
    "from char_cnn_lm_model import gated_char_cnn_model\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.variable_scope('gated_cnn'):\n",
    "        model = gated_char_cnn_model(conf, is_bidirectional=False)\n",
    "        all_variables = tf.get_collection_ref(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        var_list=[v for v in all_variables if \"Adagrad\" not in v.name]\n",
    "    with tf.variable_scope('gated_cnn', reuse=True):\n",
    "        model_test = gated_char_cnn_model(conf, is_train=False, is_bidirectional=False)\n",
    "    with tf.variable_scope('gated_cnn', reuse=True):\n",
    "        model_single = gated_char_cnn_model(single_config, is_train=False, is_bidirectional=False)    \n",
    "    saver = tf.train.Saver(var_list=var_list)\n",
    "    print(\"Started Model Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_idx = 0\n",
    "# with tf.Session(graph=graph) as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     summary_writer = tf.summary.FileWriter(conf.summary_path, graph=sess.graph)\n",
    "\n",
    "#     if os.path.exists(conf.ckpt_file+'.index'):\n",
    "#         saver.restore(sess, conf.ckpt_file)\n",
    "#         print(\"Model Restored\")\n",
    "\n",
    "#     for i in np.arange(conf.epochs):\n",
    "#         start = time.time()\n",
    "#         for j in np.arange(10000):\n",
    "#         #for j in np.arange(21):\n",
    "#             x = next(data_gen)\n",
    "#             inputs, labels = x['tokens_characters'], x['next_token_id']\n",
    "#             labels = labels.reshape(-1, 1)\n",
    "#             _, l = sess.run([model.optimizer, model.loss], \n",
    "#                             feed_dict={model.X:inputs, model.y:labels})\n",
    "#             if j%200 == 0:\n",
    "#                 print('epoch'+str(i), 'loop'+str(j), l)\n",
    "#             if j%2000 == 1999:\n",
    "#                 perp = sess.run(model.perplexity, \n",
    "#                                 feed_dict={model.X:inputs, model.y:labels})\n",
    "#                 print(\"Perplexity: %.2f\"%perp)\n",
    "#                 saver.save(sess, conf.ckpt_file)\n",
    "#         end = time.time()\n",
    "#         print(\"Epoch: %.2f, Time: %.2f,  Loss: %.2f\"%(i, end-start, l))\n",
    "\n",
    "#         if i % 2 == 0:\n",
    "#             perp = sess.run(model.perplexity, feed_dict={model.X:inputs, model.y:labels})\n",
    "#             print(\"Perplexity: %.2f\"%perp)\n",
    "#             saver.save(sess, conf.ckpt_file)\n",
    "\n",
    "#         #summaries = sess.run(model.merged_summary_op, feed_dict={model.X:inputs, model.y:labels})\n",
    "#         #summary_writer.add_summary(summaries, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "In this part, we need to use other datasets for sentiment analysis, like IMDB datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv('data/movie_data/IMDB_review_train.csv', index_col=0)\n",
    "file_test = pd.read_csv('data/movie_data/IMDB_review_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, y_train = file_train.text.values, file_train.sentiment.values\n",
    "text_test, y_test = file_test.text.values, file_test.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map text in to sequence of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sents_handler import generate_char_samples\n",
    "train_gs = generate_char_samples(text_train, y_train, vocab_file, 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs, sent_labels, lengths = train_gs.generate(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, we fill the unknow letters as 261, not 0, this is very important.\n",
    "def sent_emb_padding(sent_vecs):\n",
    "    shape = sent_vecs.shape\n",
    "    sent_char_matrix = np.ones([shape[0], 50, 50])*261\n",
    "    if shape[1] < 50:\n",
    "        sent_char_matrix[:, :shape[1], :] = sent_vecs[:, :, :]\n",
    "    else:\n",
    "        sent_char_matrix = sent_vecs[:, :50, :]\n",
    "    return sent_char_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 50, 50)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vecs = sent_emb_padding(sent_vecs)\n",
    "sent_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bilm import Batcher, TokenBatcher\n",
    "batcher = Batcher(vocab_file, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([259, 257, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "       261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "       261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "       261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_words=[['i', 'love', 'meat'], ['what', 'a', 'good', 'day']]\n",
    "batcher.batch_sentences(list(sents_words))[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the contextualized representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ckpt_char_gated_cnn/vocab267743_embed128_filters64_batch64_layers3_block3_fdim5/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess_lm = tf.Session(graph=graph)\n",
    "saver.restore(sess_lm, conf.ckpt_file)\n",
    "def sent2vec(inputs, sess):\n",
    "    '''Get word representations'''\n",
    "    #Get the contextualized representation\n",
    "    #train_gs = generate_samples(np.array(text_train), np.array(y_train), word_to_idx, 20, False)\n",
    "    #sent_vecs, sent_labels, lengths = train_gs.generate(32)\n",
    "    assert inputs.shape[0] == conf.batch_size\n",
    "    out_layer = sess.run(model_test.hidden_layer, feed_dict={model_test.X:inputs})\n",
    "    return out_layer\n",
    "\n",
    "def sent2vec_single(inputs, sess):\n",
    "    '''Get word representations'''\n",
    "    #Get the contextualized representation\n",
    "    #train_gs = generate_samples(np.array(text_train), np.array(y_train), word_to_idx, 20, False)\n",
    "    #sent_vecs, sent_labels, lengths = train_gs.generate(32)\n",
    "    assert inputs.shape[0] == 1\n",
    "    out_layer = sess.run(model_single.hidden_layer, feed_dict={model_single.X:inputs})\n",
    "    return out_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "sent_vecs, sent_labels, lengths = train_gs.generate(64) \n",
    "sent_vecs = sent_emb_padding(sent_vecs)\n",
    "print(sent_vecs.shape)\n",
    "out_layer = sent2vec(sent_vecs, sess_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import utils as nn_utils\n",
    "class CNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, filters, embedding_dim, kernel_num, label_size):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.filter_sizes = filters\n",
    "        #self.convs = []\n",
    "        #self.maxpools = []\n",
    "        #self.avgpools = []\n",
    "        #self.conv = nn.Conv2d(1, kernel_num, (3, embedding_dim))\n",
    "        #Convlutional layer\n",
    "        for i, filter_size in enumerate(self.filter_sizes):\n",
    "            conv = nn.Conv2d(1, kernel_num, (filter_size, embedding_dim))\n",
    "            setattr(self, 'conv_{i}', conv)\n",
    "            \n",
    "            #Max pooling\n",
    "            maxpool = nn.MaxPool2d((1, max_word_len-filter_size+1), 1)\n",
    "            setattr(self, 'maxpool_{i}', maxpool)\n",
    "            #self.maxpools.append(maxpool)\n",
    "            #Average pooling\n",
    "            avgpool = nn.AvgPool2d((1, max_word_len-filter_size+1), 1)\n",
    "            setattr(self, 'avgpool_{i}', avgpool)\n",
    "            #self.avgpools.append(avgpool)\n",
    "            \n",
    "        self.kernel_num = kernel_num\n",
    "        \n",
    "        num = len(self.filter_sizes)\n",
    "        \n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2label = nn.Linear((2*kernel_num)*num, label_size)\n",
    "        #self.batch_size = batch_size\n",
    "        #self.hidden = self.init_hidden(batch_size)\n",
    "    def get_conv(self, i):\n",
    "        return getattr(self, 'conv_{i}')\n",
    "    \n",
    "    def get_maxpool(self, i):\n",
    "        return getattr(self, 'maxpool_{i}')\n",
    "    \n",
    "    def get_avgpool(self, i):\n",
    "        return getattr(self, 'avgpool_{i}')\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        #Batch_size, word_len, emb_size\n",
    "        #embeds = self.word_embeddings(sentence)\n",
    "        dropout = nn.Dropout(0.5)\n",
    "        #embeds = nn.Dropout(sentence, 0.2, self.training)\n",
    "        embeds = sentence\n",
    "        if self.training:\n",
    "            embeds = dropout(embeds)\n",
    "        size = embeds.size()\n",
    "        ##Batch_size, 1, word_len, emb_size\n",
    "        inputs = embeds.view((size[0], 1, size[1], size[2]))\n",
    "        #Batch_size, out_channel, n-stride+1, 1\n",
    "        pools = []\n",
    "  \n",
    "        #pool = torch.cat([max_pool, avg_pool], dim=1)\n",
    "        for i in range(len(self.filter_sizes)):\n",
    "            outputs = self.get_conv(i)(inputs)\n",
    "            outputs = outputs.view((size[0], 1, self.kernel_num, -1))\n",
    "            outputs = F.relu(outputs)\n",
    "            max_pool = self.get_maxpool(i)(outputs).squeeze(dim=1).squeeze(dim=2)\n",
    "            avg_pool = self.get_avgpool(i)(outputs).squeeze(dim=1).squeeze(dim=2)\n",
    "            pool = torch.cat([max_pool, avg_pool], dim=1)\n",
    "            pools.append(pool)\n",
    "            \n",
    "        pooled = torch.cat(pools, dim=1)\n",
    "        #print(pooled.size())\n",
    "        #fully connected layer\n",
    "        pooled = F.dropout(pooled, 0.5, self.training)\n",
    "        probs = self.hidden2label(pooled)\n",
    "\n",
    "        pred_scores = F.log_softmax(probs, dim=1)\n",
    "        return pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [3]\n",
    "model = CNNClassifier(filters, 350, 128, 2)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "0.7150627970695496\n",
      "0.7172332406044006\n",
      "0.6893958449363708\n",
      "0.670016884803772\n",
      "0.7130548357963562\n",
      "Epoch: 1\n",
      "0.7191800475120544\n",
      "0.7569373250007629\n",
      "0.7279062867164612\n",
      "0.7354917526245117\n",
      "0.7272653579711914\n",
      "Epoch: 2\n",
      "0.7073136568069458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-0efb5fd4ea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msent_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0msent_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_emb_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mout_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_lm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Language-Modeling-GatedCNN-master/sents_handler.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    240\u001b[0m             sent_vecs, sent_labels, lengths = self.generate_random_samples(self.data, \n\u001b[1;32m    241\u001b[0m                                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                                                               batch_size)\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Language-Modeling-GatedCNN-master/sents_handler.py\u001b[0m in \u001b[0;36mgenerate_random_samples\u001b[0;34m(self, sents, labels, batch_size)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m#sent_vecs, sent_lens = self.create_sent_idx(sents)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0msent_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sent_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msent_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_lens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m#return self.create_sent_idx(sents), labels, sent_lens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Language-Modeling-GatedCNN-master/sents_handler.py\u001b[0m in \u001b[0;36mcreate_sent_idx\u001b[0;34m(self, sents)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mMap\u001b[0m \u001b[0msents\u001b[0m \u001b[0minto\u001b[0m \u001b[0mchar\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         '''\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0msents_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0msents_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msents_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0msents_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Language-Modeling-GatedCNN-master/sents_handler.py\u001b[0m in \u001b[0;36msent2idx\u001b[0;34m(self, sent)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;34m'''Map a sentence into a sequence of idx'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0msent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m##Cut long sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Language-Modeling-GatedCNN-master/sents_handler.py\u001b[0m in \u001b[0;36msent_split\u001b[0;34m(self, sent)\u001b[0m\n\u001b[1;32m    193\u001b[0m         '''\n\u001b[1;32m    194\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__call__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.get_batch_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         X, bp_layer = layer.begin_update(layer.ops.flatten(seqs_in, pad=pad),\n\u001b[0;32m--> 280\u001b[0;31m                                          drop=drop)\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36muniqued_fwd\u001b[0;34m(X, drop)\u001b[0m\n\u001b[1;32m    372\u001b[0m                                                     return_counts=True)\n\u001b[1;32m    373\u001b[0m         \u001b[0mX_uniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mY_uniq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_Y_uniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_uniq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_uniq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY_uniq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0muniqued_bwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mbest__bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich__bo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mbest__bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest__bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "loops = int(len(text_train)/batch_size)\n",
    "losses = []\n",
    "model.train()\n",
    "for i in np.arange(epochs):\n",
    "    total_loss = 0\n",
    "    print('Epoch:', i)\n",
    "    for j in np.arange(loops):\n",
    "        sent_vecs, sent_labels, lengths = train_gs.generate(64) \n",
    "        sent_vecs = sent_emb_padding(sent_vecs)#Padding\n",
    "        out_layer = sent2vec(sent_vecs, sess_lm)\n",
    "        sents = torch.FloatTensor(out_layer)\n",
    "        model.zero_grad()\n",
    "        outputs = model(sents)\n",
    "        loss = loss_function(outputs, torch.LongTensor(sent_labels))\n",
    "        \n",
    "        #regularizer\n",
    "        l2_reg = torch.tensor(0.)\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += l2_reg * 0.001\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "        if j%80 == 0:\n",
    "            print(loss.item())\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gs = generate_char_samples(text_train, y_train, vocab_file, 50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.620803886925795\n",
      "Macro F1: 0.5576409866526607\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Model\n",
    "from sklearn.metrics import f1_score\n",
    "loops = len(y_train)\n",
    "correct_num = 0\n",
    "predictions = []\n",
    "for i in np.arange(loops):\n",
    "    model.eval()\n",
    "    sent_vecs, sent_labels, lengths = test_gs.generate(1)\n",
    "    sent_vecs = sent_emb_padding(sent_vecs)#Padding\n",
    "    out_layer = sent2vec_single(sent_vecs, sess_lm)\n",
    "    sents = torch.FloatTensor(out_layer)\n",
    "    outputs = model(sents)\n",
    "    #Compare prediction\n",
    "    pred = outputs.argmax(dim=1).numpy()[0]\n",
    "    predictions.append(pred)\n",
    "    count = sum(outputs.argmax(dim=1).numpy() == sent_labels)\n",
    "    correct_num += count\n",
    "print('Accuracy:', correct_num/loops)\n",
    "print('Macro F1:', f1_score(y_train, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12503"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
