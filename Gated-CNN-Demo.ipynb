{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep contextualized word representation has drawn wide attention because of state-of-the-art performances in downstream tasks. Contextualized embeddings can capture not only word-level information but also multi-sense information, thus improving the results in sentiment analysis, SQuad and etc. However, the language adopted in the [Elmo](https://allennlp.org/elmo) model were biLSTMs which contained a huge number of parameters, it was less likely for small labs to train and run such experiments.\n",
    "\n",
    "\n",
    "In this project, we intend to make use of CNN language model in learning efficient word representations for sentiment analysis. We train a language model based on [Gated CNN architecture](https://arxiv.org/abs/1612.08083) proposed by Yann Daulphin, then do sentiment analysis with embeddings generated by the language model.\n",
    "\n",
    "The language model training dataset is 1-billion-word-language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "from model import *\n",
    "from data_utils import data_helper\n",
    "from conf_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the configuration and prepare data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    vocab_size = 2000\n",
    "    embedding_size = 200\n",
    "    filter_size = 64\n",
    "    num_layers = 1\n",
    "    block_size = 2\n",
    "    filter_h = 5\n",
    "    context_size = 20\n",
    "    text_size = context_size\n",
    "    batch_size = 16\n",
    "    epochs = 5\n",
    "    num_sampled = 64\n",
    "    learning_rate = 0.0001\n",
    "    momentum = 0.99\n",
    "    grad_clip = 0.1\n",
    "    num_batches = 0\n",
    "    ckpt_path = 'ckpt'\n",
    "    summary_path = 'logs'\n",
    "    #data_dir = \"data/texts/reviews/movie_reviews\"\n",
    "    data_dir = \"data/1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize configuration files\n",
    "conf = prepare_conf(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data batches for language model training\n",
    "dh = data_helper(conf)\n",
    "x_batches, y_batches, word_to_idx, idx_to_word = dh.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,  67,   0,   6,  57,   0, 611, 134, 650,   7,   0,  46,\n",
       "        14,   9,   0, 427,  31, 785,   4,   3,   1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batches[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a CNN-based language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"layer_0/mul:0\", shape=(16, 22, 1, 64), dtype=float32)\n",
      "Started Model Training...\n"
     ]
    }
   ],
   "source": [
    "#Create a language model\n",
    "#Note we need to save the models for subsequent tasks\n",
    "model = GatedCNN(conf)\n",
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "print(\"Started Model Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from RNN import RNN\n",
    "#model = RNN(conf)\n",
    "#saver = tf.train.Saver(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(352, 1) dtype=int32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.26772\n",
      "227.70192\n",
      "227.99956\n",
      "208.36089\n",
      "212.4167\n",
      "203.27255\n",
      "224.46005\n",
      "185.67218\n",
      "177.58745\n",
      "188.18663\n",
      "146.32607\n",
      "168.51358\n",
      "150.96786\n",
      "156.16171\n",
      "145.6881\n",
      "179.34212\n",
      "152.08679\n",
      "137.91362\n",
      "97.152664\n",
      "113.898895\n",
      "121.605545\n",
      "139.27708\n",
      "119.64997\n",
      "118.64231\n",
      "134.82767\n",
      "143.98682\n",
      "100.1643\n",
      "105.68909\n",
      "121.312454\n",
      "98.34222\n",
      "81.95305\n",
      "126.8116\n",
      "83.44582\n",
      "84.46463\n",
      "93.157814\n",
      "56.46525\n",
      "43.83351\n",
      "137.56476\n",
      "117.19837\n",
      "107.361275\n",
      "57.000698\n",
      "52.777164\n",
      "97.905075\n",
      "75.96489\n",
      "53.79938\n",
      "60.598644\n",
      "80.37415\n",
      "22.863533\n",
      "83.861374\n",
      "68.35846\n",
      "65.68785\n",
      "54.80743\n",
      "42.50838\n",
      "52.88417\n",
      "74.56658\n",
      "36.594654\n",
      "41.575573\n",
      "44.01676\n",
      "47.03163\n",
      "59.84403\n",
      "53.362564\n",
      "45.595596\n",
      "46.375626\n",
      "31.009205\n",
      "14.648789\n",
      "35.55819\n",
      "44.863823\n",
      "34.07427\n",
      "53.857216\n",
      "26.458221\n",
      "43.773563\n",
      "31.37784\n",
      "51.65635\n",
      "27.37025\n",
      "19.509045\n",
      "29.14902\n",
      "66.71709\n",
      "39.638447\n",
      "21.53565\n",
      "37.455814\n",
      "21.847406\n",
      "47.036217\n",
      "37.34256\n",
      "21.799898\n",
      "23.319324\n",
      "43.41062\n",
      "39.995777\n",
      "29.902403\n",
      "22.831322\n",
      "29.286768\n",
      "14.550912\n",
      "46.84936\n",
      "24.484896\n",
      "24.686182\n",
      "37.054104\n",
      "35.073746\n",
      "21.852516\n",
      "20.087107\n",
      "40.469498\n",
      "18.264572\n",
      "12.286408\n",
      "44.487442\n",
      "54.399315\n",
      "22.54781\n",
      "16.600445\n",
      "20.222527\n",
      "42.83325\n",
      "26.254242\n",
      "20.668814\n",
      "33.88345\n",
      "13.9983425\n",
      "15.209595\n",
      "21.923374\n",
      "9.658329\n",
      "19.840643\n",
      "47.13572\n",
      "39.650265\n",
      "27.353565\n",
      "27.683455\n",
      "11.83424\n",
      "29.093933\n",
      "30.680748\n",
      "28.789135\n",
      "21.06177\n",
      "11.410425\n",
      "14.208398\n",
      "11.993778\n",
      "16.524036\n",
      "23.524603\n",
      "16.863962\n",
      "18.781189\n",
      "41.457558\n",
      "30.1705\n",
      "22.065636\n",
      "13.010255\n",
      "8.964054\n",
      "10.619544\n",
      "44.987827\n",
      "12.269257\n",
      "31.214039\n",
      "31.127941\n",
      "23.741444\n",
      "28.227924\n",
      "22.157238\n",
      "11.3028\n",
      "8.862091\n",
      "12.591123\n",
      "8.317721\n",
      "11.073675\n",
      "9.201435\n",
      "6.1125474\n",
      "8.900861\n",
      "14.843494\n",
      "10.19867\n",
      "8.946554\n",
      "20.413857\n",
      "21.102554\n",
      "29.60011\n",
      "16.236399\n",
      "7.6802735\n",
      "10.825718\n",
      "7.4001584\n",
      "9.480905\n",
      "11.573233\n",
      "21.613556\n",
      "14.295083\n",
      "11.144842\n",
      "8.670453\n",
      "8.333667\n",
      "10.122378\n",
      "8.01141\n",
      "8.014423\n",
      "9.579158\n",
      "8.835287\n",
      "9.366567\n",
      "7.714786\n",
      "8.049138\n",
      "6.1611896\n",
      "9.376491\n",
      "7.6013656\n",
      "8.199721\n",
      "9.410684\n",
      "15.057511\n",
      "8.848306\n",
      "23.225084\n",
      "17.178856\n",
      "20.096668\n",
      "14.220211\n",
      "6.6301875\n",
      "10.130009\n",
      "7.6826825\n",
      "8.986169\n",
      "9.258287\n",
      "8.30487\n",
      "7.066277\n",
      "6.8577175\n",
      "6.77661\n",
      "6.542484\n",
      "7.14745\n",
      "7.5428867\n",
      "11.156907\n",
      "7.9425907\n",
      "6.7177367\n",
      "6.358017\n",
      "12.346326\n",
      "12.328256\n",
      "6.038708\n",
      "8.20498\n",
      "7.1268864\n",
      "7.9217067\n",
      "13.956302\n",
      "5.114429\n",
      "6.283837\n",
      "7.401569\n",
      "22.847939\n",
      "6.09267\n",
      "8.72014\n",
      "7.2790437\n",
      "7.6257358\n",
      "6.3416076\n",
      "6.449385\n",
      "5.6033583\n",
      "5.0708523\n",
      "5.174881\n",
      "7.6493883\n",
      "5.4326553\n",
      "5.4232006\n",
      "4.8598385\n",
      "6.907718\n",
      "4.39381\n",
      "8.06095\n",
      "10.202642\n",
      "5.284501\n",
      "8.629149\n",
      "5.9896975\n",
      "6.6492476\n",
      "5.6907125\n",
      "6.080882\n",
      "6.3685656\n",
      "6.003981\n",
      "6.9179564\n",
      "9.7266035\n",
      "5.026196\n",
      "7.676186\n",
      "4.8204503\n",
      "6.277979\n",
      "6.8767695\n",
      "6.420242\n",
      "6.4432235\n",
      "9.288563\n",
      "4.688546\n",
      "5.4089274\n",
      "6.6007357\n",
      "4.04993\n",
      "5.9963274\n",
      "5.4982486\n",
      "8.561186\n",
      "5.536617\n",
      "4.2251463\n",
      "5.207702\n",
      "7.136737\n",
      "4.7360835\n",
      "16.58258\n",
      "3.9095576\n",
      "7.398048\n",
      "6.075388\n",
      "6.3885884\n",
      "6.169844\n",
      "4.525146\n",
      "5.6144214\n",
      "6.5796447\n",
      "7.063063\n",
      "6.265394\n",
      "4.70762\n",
      "4.4145474\n",
      "5.9022155\n",
      "5.8071017\n",
      "5.622891\n",
      "4.7414465\n",
      "6.6496425\n",
      "5.37611\n",
      "5.7061944\n",
      "6.04808\n",
      "6.573538\n",
      "4.8535233\n",
      "5.1803684\n",
      "6.490517\n",
      "4.9234276\n",
      "5.3587093\n",
      "5.6210437\n",
      "6.1846514\n",
      "5.9331007\n",
      "5.298141\n",
      "6.6122546\n",
      "5.728348\n",
      "5.0996203\n",
      "5.686703\n",
      "5.345261\n",
      "4.3312035\n",
      "5.5435505\n",
      "5.5002384\n",
      "4.982709\n",
      "6.036192\n",
      "7.826555\n",
      "4.7033\n",
      "4.511616\n",
      "5.628811\n",
      "7.2723546\n",
      "5.483621\n",
      "5.4621906\n",
      "4.989159\n",
      "4.8307166\n",
      "5.3382497\n",
      "4.284432\n",
      "3.2620163\n",
      "4.558697\n",
      "5.173459\n",
      "4.373359\n",
      "4.028994\n",
      "4.222575\n",
      "5.436359\n",
      "5.7983885\n",
      "3.484627\n",
      "5.9795213\n",
      "4.3265533\n",
      "3.874215\n",
      "5.0221343\n",
      "4.604434\n",
      "5.0944285\n",
      "4.4970903\n",
      "6.6673126\n",
      "4.4926\n",
      "6.4860535\n",
      "6.448392\n",
      "3.9760756\n",
      "3.9251478\n",
      "4.610788\n",
      "3.926273\n",
      "4.7665706\n",
      "4.1111646\n",
      "4.0983987\n",
      "4.6093245\n",
      "4.6411967\n",
      "4.95383\n",
      "4.702818\n",
      "5.41484\n",
      "4.6299148\n",
      "4.7662296\n",
      "4.2077246\n",
      "4.6322813\n",
      "4.249886\n",
      "3.8195298\n",
      "4.521338\n",
      "3.4009588\n",
      "5.624313\n",
      "4.676892\n",
      "4.5720377\n",
      "4.8245106\n",
      "5.2049885\n",
      "5.1581845\n",
      "4.710107\n",
      "4.2321963\n",
      "5.769469\n",
      "3.7315862\n",
      "5.104282\n",
      "3.561663\n",
      "5.4333496\n",
      "4.950433\n",
      "5.382428\n",
      "4.0994887\n",
      "4.686523\n",
      "4.0456595\n",
      "4.5824475\n",
      "4.6419888\n",
      "3.4430587\n",
      "4.828877\n",
      "5.9511294\n",
      "4.8632107\n",
      "3.4352312\n",
      "4.2373486\n",
      "4.6587725\n",
      "4.263159\n",
      "4.1025004\n",
      "3.5022233\n",
      "3.1902382\n",
      "5.581516\n",
      "3.7134225\n",
      "4.4325347\n",
      "4.8258944\n",
      "4.7231374\n",
      "4.858842\n",
      "4.598333\n",
      "3.9264505\n",
      "3.512646\n",
      "5.2482395\n",
      "4.39334\n",
      "4.676817\n",
      "4.441541\n",
      "4.1123934\n",
      "4.1432147\n",
      "3.893775\n",
      "4.6731358\n",
      "4.133112\n",
      "4.127891\n",
      "4.2149334\n",
      "3.3088713\n",
      "3.8692122\n",
      "3.2056046\n",
      "4.080565\n",
      "3.9522018\n",
      "4.242533\n",
      "5.0207157\n",
      "3.2189515\n",
      "3.8863866\n",
      "4.348041\n",
      "4.3611903\n",
      "5.0582\n",
      "3.4725091\n",
      "4.676846\n",
      "3.1718528\n",
      "3.8921938\n",
      "3.4188871\n",
      "3.8548806\n",
      "4.231105\n",
      "4.2002764\n",
      "5.2510242\n",
      "4.150368\n",
      "4.5301166\n",
      "5.5926137\n",
      "3.0888214\n",
      "4.505342\n",
      "4.441872\n",
      "3.4362562\n",
      "4.4403005\n",
      "3.4446595\n",
      "3.8115914\n",
      "3.1857612\n",
      "4.003799\n",
      "3.3797686\n",
      "4.375244\n",
      "3.6013162\n",
      "3.602048\n",
      "3.1976392\n",
      "3.969776\n",
      "3.9829972\n",
      "3.9659004\n",
      "4.6535325\n",
      "4.1608768\n",
      "3.327706\n",
      "3.918802\n",
      "4.230168\n",
      "3.2833395\n",
      "3.6547532\n",
      "3.0247605\n",
      "3.5607054\n",
      "5.5853114\n",
      "3.4469712\n",
      "2.9774024\n",
      "2.999478\n",
      "4.9199452\n",
      "2.8672886\n",
      "3.6996903\n",
      "3.8413086\n",
      "3.0744987\n",
      "3.4696379\n",
      "4.3021083\n",
      "3.9485388\n",
      "3.7281828\n",
      "3.5498312\n",
      "3.7713637\n",
      "3.3662431\n",
      "2.9780045\n",
      "2.9139488\n",
      "3.3760622\n",
      "3.1720123\n",
      "4.0613627\n",
      "2.9364138\n",
      "4.6817975\n",
      "2.863117\n",
      "4.0018377\n",
      "3.685708\n",
      "4.7466993\n",
      "3.9954875\n",
      "2.760188\n",
      "3.4104867\n",
      "3.55803\n",
      "3.6121178\n",
      "3.0433874\n",
      "4.5135574\n",
      "3.8624282\n",
      "2.8963752\n",
      "3.0014732\n",
      "3.2871447\n",
      "3.8549562\n",
      "3.685105\n",
      "3.5408118\n",
      "3.128617\n",
      "3.0418694\n",
      "3.7673833\n",
      "3.7742858\n",
      "3.3478372\n",
      "4.111741\n",
      "3.3133385\n",
      "3.3040183\n",
      "4.087772\n",
      "3.8027062\n",
      "4.3144803\n",
      "4.014199\n",
      "2.932714\n",
      "2.8345277\n",
      "3.6154184\n",
      "3.8956583\n",
      "3.799614\n",
      "3.3043082\n",
      "3.639158\n",
      "4.1062922\n",
      "3.3095343\n",
      "3.5013711\n",
      "3.8533387\n",
      "3.4785216\n",
      "2.9424791\n",
      "3.6718404\n",
      "3.6513472\n",
      "3.1291275\n",
      "3.4927933\n",
      "3.4413831\n",
      "2.981291\n",
      "3.558213\n",
      "3.0087328\n",
      "3.3581748\n",
      "2.9308984\n",
      "3.9879332\n",
      "3.486831\n",
      "3.037439\n",
      "2.964672\n",
      "3.253066\n",
      "3.4187531\n",
      "3.2891843\n",
      "2.9872096\n",
      "3.1731591\n",
      "3.192733\n",
      "2.9522867\n",
      "2.7838678\n",
      "3.0939672\n",
      "3.4978073\n",
      "3.2095962\n",
      "3.1586998\n",
      "2.8422296\n",
      "3.5529847\n",
      "3.201612\n",
      "3.5727723\n",
      "3.3980372\n",
      "3.1466067\n",
      "3.7019355\n",
      "2.9452667\n",
      "2.7369874\n",
      "3.089691\n",
      "2.895569\n",
      "3.2829707\n",
      "2.9501371\n",
      "3.333731\n",
      "3.382193\n",
      "3.4528656\n",
      "3.8324966\n",
      "2.9664712\n",
      "2.8601396\n",
      "2.881351\n",
      "2.7506793\n",
      "2.6106117\n",
      "2.9213684\n",
      "3.1328516\n",
      "4.0805483\n",
      "2.7684422\n",
      "2.7179687\n",
      "3.2960017\n",
      "2.6908839\n",
      "2.746339\n",
      "3.1244643\n",
      "3.1117685\n",
      "2.9344423\n",
      "3.114395\n",
      "3.4672918\n",
      "4.2387595\n",
      "2.831909\n",
      "2.9207232\n",
      "3.9865026\n",
      "2.8598695\n",
      "2.963935\n",
      "2.9115326\n",
      "3.2322416\n",
      "2.8167117\n",
      "2.808871\n",
      "2.8773513\n",
      "3.084473\n",
      "2.8448052\n",
      "2.583605\n",
      "4.227926\n",
      "3.012451\n",
      "2.3150866\n",
      "2.7241929\n",
      "2.9279146\n",
      "2.5332193\n",
      "2.6682882\n",
      "2.835327\n",
      "2.5437791\n",
      "2.6389055\n",
      "2.783361\n",
      "2.943231\n",
      "3.198521\n",
      "2.94699\n",
      "3.227272\n",
      "3.6462297\n",
      "2.9301767\n",
      "2.5553746\n",
      "3.1126204\n",
      "2.9278128\n",
      "2.425326\n",
      "2.9524138\n",
      "2.7788885\n",
      "2.7729516\n",
      "3.2694695\n",
      "2.550191\n",
      "3.101471\n",
      "2.3911614\n",
      "2.559002\n",
      "2.8388186\n",
      "2.7704694\n",
      "2.7612631\n",
      "3.2172341\n",
      "2.9685557\n",
      "2.69368\n",
      "2.5690935\n",
      "3.1607134\n",
      "3.050659\n",
      "2.5961752\n",
      "3.1234667\n",
      "2.6159086\n",
      "2.3777022\n",
      "2.467398\n",
      "3.0112\n",
      "2.7659643\n",
      "3.1534293\n",
      "2.9821012\n",
      "2.402218\n",
      "2.7609105\n",
      "2.6840143\n",
      "2.9520302\n",
      "2.5678144\n",
      "2.75489\n",
      "2.8119917\n",
      "2.6389408\n",
      "2.885055\n",
      "2.4674904\n",
      "2.974414\n",
      "2.7591393\n",
      "2.4551513\n",
      "2.815117\n",
      "2.677874\n",
      "2.8294883\n",
      "2.9498153\n",
      "2.7267778\n",
      "2.5253084\n",
      "3.142473\n",
      "2.945571\n",
      "2.6068544\n",
      "2.6628363\n",
      "2.72975\n",
      "3.1150384\n",
      "2.7756515\n",
      "2.7016788\n",
      "3.1568422\n",
      "3.053186\n",
      "2.5239923\n",
      "2.752157\n",
      "2.8618255\n",
      "2.7021053\n",
      "2.6096096\n",
      "2.6897058\n",
      "2.5221114\n",
      "2.8384671\n",
      "2.0374024\n",
      "2.8443272\n",
      "2.3637927\n",
      "3.0286562\n",
      "2.4699163\n",
      "2.3471694\n",
      "2.7343636\n",
      "2.6278114\n",
      "2.7805939\n",
      "2.937131\n",
      "2.4296827\n",
      "2.5085936\n",
      "3.362194\n",
      "3.1260183\n",
      "3.0249624\n",
      "2.7593591\n",
      "2.5932753\n",
      "2.5760238\n",
      "2.699219\n",
      "2.4107478\n",
      "2.6837351\n",
      "3.1525588\n",
      "2.330491\n",
      "2.7986674\n",
      "2.7070532\n",
      "2.8907087\n",
      "2.7645662\n",
      "2.529855\n",
      "2.5724592\n",
      "2.4579992\n",
      "2.477268\n",
      "3.3323088\n",
      "2.6485076\n",
      "2.7903106\n",
      "2.4365637\n",
      "2.3450334\n",
      "2.7876687\n",
      "2.6228933\n",
      "2.2516723\n",
      "2.466559\n",
      "2.7387407\n",
      "2.3282232\n",
      "2.647954\n",
      "2.6934652\n",
      "2.9905403\n",
      "2.7203634\n",
      "2.660933\n",
      "2.5676558\n",
      "2.420368\n",
      "2.523954\n",
      "2.4840472\n",
      "3.0791578\n",
      "2.5418031\n",
      "2.450089\n",
      "2.633317\n",
      "2.482919\n",
      "3.1706061\n",
      "2.5642574\n",
      "2.6015122\n",
      "2.170954\n",
      "2.4712741\n",
      "2.5629408\n",
      "2.5167694\n",
      "2.2071748\n",
      "2.5979283\n",
      "2.4268084\n",
      "2.5316343\n",
      "2.7521658\n",
      "2.869122\n",
      "2.5423086\n",
      "2.8326294\n",
      "2.4588244\n",
      "2.3973768\n",
      "2.3798583\n",
      "2.7823703\n",
      "2.7147024\n",
      "2.7241232\n",
      "2.277257\n",
      "2.6869562\n",
      "2.4058619\n",
      "2.572167\n",
      "2.4786763\n",
      "2.3762732\n",
      "3.0850646\n",
      "2.8880339\n",
      "2.4666827\n",
      "2.373992\n",
      "2.517293\n",
      "2.0918303\n",
      "2.854259\n",
      "2.3608377\n",
      "2.3151023\n",
      "2.342312\n",
      "2.4410708\n",
      "2.327112\n",
      "2.640487\n",
      "2.566755\n",
      "2.2956326\n",
      "2.4256418\n",
      "2.64247\n",
      "2.3330278\n",
      "2.3502314\n",
      "2.1105163\n",
      "2.3546739\n",
      "2.5151124\n",
      "2.3220901\n",
      "2.434518\n",
      "2.3825176\n",
      "2.396987\n",
      "2.4578102\n",
      "2.5221317\n",
      "2.6164186\n",
      "2.497047\n",
      "2.6143112\n",
      "2.3468614\n",
      "2.6391652\n",
      "2.594288\n",
      "2.5499911\n",
      "2.3746033\n",
      "2.2187252\n",
      "2.3065405\n",
      "2.811671\n",
      "2.390824\n",
      "2.107571\n",
      "2.2486315\n",
      "2.7995954\n",
      "2.1181076\n",
      "2.0808954\n",
      "2.3134153\n",
      "3.009752\n",
      "2.2784417\n",
      "2.56543\n",
      "2.288874\n",
      "2.555802\n",
      "2.3006911\n",
      "2.512112\n",
      "2.1237624\n",
      "2.2087593\n",
      "2.4630857\n",
      "2.4697564\n",
      "2.3577192\n",
      "2.3143632\n",
      "2.5568967\n",
      "2.4376185\n",
      "2.2817178\n",
      "2.411979\n",
      "2.3241193\n",
      "2.4712706\n",
      "2.3562307\n",
      "2.473204\n",
      "2.2498708\n",
      "2.273691\n",
      "2.1456435\n",
      "2.2651062\n",
      "2.3239806\n",
      "2.4837797\n",
      "2.1979487\n",
      "2.438775\n",
      "2.3416717\n",
      "2.4255333\n",
      "2.685483\n",
      "2.3793178\n",
      "2.211612\n",
      "2.2677166\n",
      "2.1086667\n",
      "2.3174808\n",
      "2.3686078\n",
      "2.12346\n",
      "2.655678\n",
      "2.1430252\n",
      "2.3498352\n",
      "2.3694746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0339568\n",
      "2.3527396\n",
      "2.4298797\n",
      "2.6817396\n",
      "2.2533872\n",
      "2.2600443\n",
      "2.01495\n",
      "2.234471\n",
      "2.3969252\n",
      "2.277185\n",
      "2.3106058\n",
      "2.3131597\n",
      "2.4052653\n",
      "2.5430412\n",
      "2.205144\n",
      "2.3562438\n",
      "2.224881\n",
      "2.3156374\n",
      "2.1680062\n",
      "2.117867\n",
      "2.239049\n",
      "2.07634\n",
      "2.263456\n",
      "2.4079225\n",
      "2.548605\n",
      "2.3143923\n",
      "2.2672546\n",
      "2.0523858\n",
      "2.1438358\n",
      "2.1201627\n",
      "2.2864027\n",
      "2.2327485\n",
      "2.2195096\n",
      "2.106459\n",
      "2.387413\n",
      "2.369789\n",
      "2.1371005\n",
      "2.2776346\n",
      "2.1769857\n",
      "2.5883331\n",
      "2.165829\n",
      "1.8974999\n",
      "2.3811598\n",
      "2.034783\n",
      "2.2098422\n",
      "2.361374\n",
      "2.201789\n",
      "2.3701613\n",
      "2.4126127\n",
      "2.6131358\n",
      "2.2021182\n",
      "2.2743728\n",
      "2.285739\n",
      "2.1355612\n",
      "3.0090544\n",
      "2.4865835\n",
      "2.4310586\n",
      "2.27762\n",
      "2.1879964\n",
      "2.2732286\n",
      "2.4407802\n",
      "2.3321545\n",
      "2.255269\n",
      "2.0162382\n",
      "2.085239\n",
      "2.3517885\n",
      "2.210936\n",
      "2.2794175\n",
      "2.191223\n",
      "2.0150473\n",
      "1.9632041\n",
      "2.1461573\n",
      "2.1476204\n",
      "2.421642\n",
      "2.1116614\n",
      "2.3050086\n",
      "2.0598266\n",
      "2.1250606\n",
      "2.1899548\n",
      "2.322623\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0ace73084a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#for j in np.arange(21):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \"\"\"\n\u001b[1;32m   1253\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m     \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \"\"\"\n\u001b[1;32m   1253\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m     \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(conf.summary_path, graph=sess.graph)\n",
    "\n",
    "    #if os.path.exists(conf.ckpt_file):\n",
    "        #saver.restore(sess, conf.ckpt_file)\n",
    "        #print(\"Model Restored\")\n",
    "\n",
    "    for i in np.arange(conf.epochs):\n",
    "        start = time.time()\n",
    "        for j in np.arange(conf.num_batches):\n",
    "        #for j in np.arange(21):\n",
    "            inputs, labels, batch_idx = dh.get_batch(x_batches, y_batches, batch_idx)\n",
    "            _, l = sess.run([model.optimizer, model.loss], feed_dict={model.X:inputs, model.y:labels})\n",
    "            if j%20 == 0:\n",
    "                print(l)\n",
    "        end = time.time()\n",
    "        print(\"Epoch: %.2f, Time: %.2f,  Loss: %.2f\"%(i, end-start, l))\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            perp = sess.run(model.perplexity, feed_dict={model.X:inputs, model.y:labels})\n",
    "            print(\"Perplexity: %.2f\"%perp)\n",
    "            saver.save(sess, conf.ckpt_file)\n",
    "\n",
    "        summaries = sess.run(model.merged_summary_op, feed_dict={model.X:inputs, model.y:labels})\n",
    "        summary_writer.add_summary(summaries, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "In this part, we need to use other datasets for sentiment analysis, like the one of SemEval2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use spacy tokenize sentences into words\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en\n",
    "#import spacy\n",
    "#nlp = spacy.load('en')\n",
    "#def sent_split(sent):\n",
    "    #words = []\n",
    "    #sent = nlp(sent.strip())\n",
    "    #for w in sent:\n",
    "        #words.append(w.text.lower())\n",
    "    #return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'data/semeval/downloaded.tsv'\n",
    "file_dev = 'data/semeval/dev_downloaded.tsv'\n",
    "file_test = 'data/semeval/test.txt'\n",
    "with open(file_train) as f:\n",
    "    tweets_train = f.readlines()\n",
    "with open(file_dev) as f:\n",
    "    tweets_dev = f.readlines()\n",
    "with open(file_test) as f:\n",
    "    tweets_test = f.readlines()\n",
    "    \n",
    "\n",
    "\n",
    "#Filter empty tweets\n",
    "def is_available(text):\n",
    "    if 'Not Available' in text:\n",
    "        return False\n",
    "    if '\\t\"objective' in text:\n",
    "        return False\n",
    "    if '\\t\"neutral' in text:\n",
    "        return False\n",
    "    if '\\tobjective' in text:\n",
    "        return False\n",
    "    if '\\tneutral' in text:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = list(filter(is_available, tweets_train))\n",
    "tweets_dev = list(filter(is_available, tweets_dev))\n",
    "tweets_test = list(filter(is_available, tweets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = [item.split('\\t') for item in tweets_train]\n",
    "tweets_dev = [item.split('\\t') for item in tweets_dev]\n",
    "tweets_test = [item.split('\\t') for item in tweets_test]\n",
    "_, _, y_train, text_train = list(zip(*tweets_train))\n",
    "_, _, y_dev, text_dev = list(zip(*tweets_dev))\n",
    "_, _, y_test, text_test = list(zip(*tweets_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, y_train = list(text_train), list(y_train)\n",
    "text_dev, y_dev = list(text_dev), list(y_dev)\n",
    "text_test, y_test = list(text_test), list(y_test)\n",
    "y_test = ['\"' + item + '\"' for item in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the labels to numbers\n",
    "from sklearn import preprocessing\n",
    "label_encode = preprocessing.LabelEncoder()  # 建立模型\n",
    "y_train = label_encode.fit_transform(y_train)\n",
    "y_dev = label_encode.transform(y_dev)\n",
    "y_test = label_encode.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sents_handler import generate_samples\n",
    "import numpy as np\n",
    "train_gs = generate_samples(np.array(text_train), np.array(y_train), word_to_idx, False)\n",
    "sent_vecs, sent_labels, lengths = train_gs.generate(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ckpt/vocab2000_embed200_filters64_batch16_layers5_block2_fdim5/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, conf.ckpt_file)\n",
    "    #Get the contextualized representation\n",
    "    out_layer = sess.run(model.out_layer, feed_dict={model.X:inputs})\n",
    "    \n",
    "    #out_layer.resha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_len = out_layer.shape[1]\n",
    "from sentiment_analysis import CNN_Model_Pretrained_Emb\n",
    "class trainConfig:\n",
    "    max_doc_len = max_word_len\n",
    "    label_size = 2\n",
    "    embed_size = 100\n",
    "    hidden_size = 250\n",
    "    batch_size = 64\n",
    "    layer_size = 2\n",
    "    \n",
    "class testConfig:\n",
    "    max_doc_len = max_word_len\n",
    "    label_size = 2\n",
    "    embed_size = 100\n",
    "    hidden_size = 250\n",
    "    batch_size = 64\n",
    "    layer_size = 2\n",
    "    \n",
    "class singleConfig:\n",
    "    max_doc_len = max_word_len\n",
    "    label_size = 2\n",
    "    embed_size = 100\n",
    "    hidden_size = 250#hidden size for hidden state of rnn\n",
    "    batch_size = 1\n",
    "    layer_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initialized!\n",
      "Model Initialized!\n",
      "Model Initialized!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "graph_cnn = tf.Graph()\n",
    "#Create models for training and testing data\n",
    "with graph_cnn.as_default():\n",
    "    initializer = tf.random_uniform_initializer(-0.02, 0.02)\n",
    "    with tf.name_scope('train'):\n",
    "        #Set different models for different buckets\n",
    "        with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
    "            train_model = CNN_Model_Pretrained_Emb(trainConfig)\n",
    "            saver=tf.train.Saver()\n",
    "    with tf.name_scope('test'):\n",
    "        #Set different models for different buckets\n",
    "        with tf.variable_scope(\"Model\", reuse=True, initializer=initializer):\n",
    "            test_model = CNN_Model_Pretrained_Emb(testConfig, False)\n",
    "            single_model = CNN_Model_Pretrained_Emb(singleConfig, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "epochs = 2\n",
    "#train_chunk_num = 10\n",
    "file = \"ckpt_cnn_pretrained_emb/cnn.ckpt\"\n",
    "with tf.Session(graph=graph_cnn) as sess:\n",
    "    #Initialize parameters\n",
    "    init = tf.global_variables_initializer()\n",
    "    if not os.path.exists(\"ckpt_cnn_pretrained_emb\"):\n",
    "        os.mkdir('ckpt_cnn_pretrained_emb')\n",
    "    if os.path.exists(\"ckpt_cnn_pretrained_emb/cnn.ckpt.index\"):\n",
    "        saver.restore(sess, file)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    start_time = time.time()\n",
    "    for m in range(epochs):\n",
    "        for i in range(train_chunk_num):\n",
    "            #sess.run(tf.assign(learning_rate, 0.002*((0.98)**m)))\n",
    "            x, y, lengths = train_gs.generate(trainConfig.batch_size)\n",
    "            feed_dict = {train_model.x:x, train_model.y:y, train_model.lengths:lengths}\n",
    "            l, _ = sess.run([train_model.cost, train_model.optimize], feed_dict=feed_dict)\n",
    "            if i%100 == 0:\n",
    "                print('Loss:', round(l, 4))\n",
    "        end_time = time.time()\n",
    "        print('Epoch', m, 'time:{:.2f}'.format(end_time - start_time))\n",
    "        \n",
    "    saver.save(sess,'ckpt_cnn_pretrained_emb/cnn.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Testing Accuracy\n",
    "with tf.Session(graph=graph_cnn) as sess:\n",
    "    print('Testing...')\n",
    "    count = 0\n",
    "    #saver = tf.train.import_meta_graph('ckpt_cnn/cnn.ckpt.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('ckpt_cnn_pretrained_emb/'))\n",
    "    print('Parameters restored')\n",
    "    start_time = time.time()\n",
    "    test_gs = generate_samples(np.array(test_processed), np.array(test_labels), False)\n",
    "    for _ in range(test_chunk_num):\n",
    "        #Traverse each data\n",
    "        x, y, lengths = test_gs.generate(testConfig.batch_size)\n",
    "        feed_dict = {test_model.x:x, test_model.y:y, test_model.lengths:lengths}\n",
    "        n = sess.run(test_model.correct_num, feed_dict=feed_dict)\n",
    "        count += np.sum(n)\n",
    "    for _ in range(remain_num):\n",
    "        #Traverse each data\n",
    "        x, y, lengths = test_gs.generate(1)\n",
    "        feed_dict = {single_model.x:x, single_model.y:y, \n",
    "                     single_model.lengths:lengths}\n",
    "        n = sess.run(single_model.correct_num, feed_dict=feed_dict)\n",
    "        count += np.sum(n)\n",
    "    end_time = time.time()\n",
    "    print('Testing Time:{:.2f}'.format(end_time - start_time))\n",
    "    print(count*1.0/len(test_processed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
